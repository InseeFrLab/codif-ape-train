{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_length = len(\"2022-10-05 11:56:15.580  INFO 8982 --- [           main] \")\n",
    "header_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_length = len(\"f.i.sirene4.repertoire.BatchApplication  \")\n",
    "event_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_line = \"2022-10-05 11:56:15.580  INFO 8982 --- [           main] f.i.sirene4.repertoire.BatchApplication  : Starting BatchApplication v2.3.3 using Java 11.0.16.1 on qfbatrelst01.ad.insee.intra with PID 8982 (/opt/insee/sirene4/qf3/lib/repertoire-batch-2.3.3.jar started by www-data in /opt/insee/sirene4/qf3/tmp)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_without_timestamp = first_line[header_length:]\n",
    "event_type = line_without_timestamp[:event_length]\n",
    "event_type.rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = line_without_timestamp[event_length + 2:]\n",
    "description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def extract_log_info(f):\n",
    "    event_types = []\n",
    "    descriptions = []\n",
    "    for line in f:\n",
    "        line_without_timestamp = line[header_length:]\n",
    "        if not line_without_timestamp:\n",
    "            continue\n",
    "        event_types.append(line_without_timestamp[:event_length].rstrip())\n",
    "        descriptions.append(line_without_timestamp[event_length + 2:])\n",
    "    return pd.DataFrame(list(zip(event_types, descriptions)), columns =['event_type', 'description'])\n",
    "\n",
    "with open(\"../data/api_log.log\") as f:\n",
    "    df = extract_log_info(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identifier = \"s.i.AbstractBatchCodificationServiceImpl\"\n",
    "log_info = \"r.b.j.c.s.i.BatchCodificationServiceImpl\"\n",
    "raw_input = \"stractLiasse1ToLiasseVarInteretProcessor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ids = df[df.event_type == identifier]\n",
    "df_ids.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info = df[df.event_type == log_info]\n",
    "df_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_input = df[df.event_type == raw_input]\n",
    "df_raw_input.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_input = df_raw_input[df_raw_input.description.str.startswith(\"LiasseVarInteretCodification\")]\n",
    "df_raw_input.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_str = df_raw_input.iloc[0, 1]\n",
    "test_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "regex = re.compile(r'norme=([^,]*),')\n",
    "matches = regex.search(test_str)\n",
    "matches.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = re.compile(r'liasseType=([^,]*),')\n",
    "matches = regex.search(test_str)\n",
    "matches.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_fields = [\n",
    "    \"norme\",\n",
    "    \"siren\",\n",
    "    \"nic\",\n",
    "    \"liasseType\",\n",
    "    \"categorieJuridique\",\n",
    "    \"domas\",\n",
    "    \"ssdom\",\n",
    "    \"domaineAssoc\",\n",
    "    \"ssDomaineAssoc\",\n",
    "    \"libelleActivitePrincipaleEtablissement\",\n",
    "    \"sedentarite\",\n",
    "    \"natureActivites\",\n",
    "    \"surface\",\n",
    "    \"lieuExercice\",\n",
    "    \"presenceSalaries\"\n",
    "]\n",
    "raw_regexes = [re.compile(r'{}'.format(field + '=([^,]*)[,\\]]')) for field in raw_fields]\n",
    "raw_regexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_raw_input(raw_input, fields, regexes):\n",
    "    raw_input_dict = {}\n",
    "    for field, regex in zip(fields, regexes):\n",
    "        matches = regex.search(raw_input)\n",
    "        raw_input_dict[field] = matches.group(1)\n",
    "    return raw_input_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_raw_input(test_str, raw_fields, raw_regexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_series = [parse_raw_input(raw_input, raw_fields, raw_regexes) for raw_input in df_raw_input.description]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(list(dict_series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_str = df_info.iloc[0, 1]\n",
    "test_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_fields = [\n",
    "    \"libelleActivite\",\n",
    "    \"natureActivites\",\n",
    "    \"liasseType\",\n",
    "    \"evenementType\",\n",
    "    \"surface\",\n",
    "    \"libelleNettoye\",\n",
    "    \"predictions\",\n",
    "    \"bilan\"\n",
    "]\n",
    "info_regexes = [re.compile(r'{}'.format(field + '=([^,]*),')) for field in info_fields]\n",
    "\n",
    "info_fields.append(\"fasttextVersion\")\n",
    "info_regexes.append(re.compile(r'fasttextVersion=([^,]*)\\]'))\n",
    "\n",
    "info_regexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_raw_input(test_str, info_fields, info_regexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_first_pred(predictions):\n",
    "    regex = re.compile(r'proposé = ([^;]*) ;.*associée = ([^;]*)\\].*proposé = ([^;]*) ;.*associée = ([^;]*)\\]')\n",
    "    matches = regex.search(predictions)\n",
    "    first_code = matches.group(1)\n",
    "    second_code = matches.group(3)\n",
    "    first_proba = matches.group(2)\n",
    "    second_proba = matches.group(4)\n",
    "    return (first_code, second_code, float(first_proba), float(second_proba))\n",
    "\n",
    "extract_first_pred(parse_raw_input(test_str, info_fields, info_regexes)[\"predictions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_series = [parse_raw_input(info_input, info_fields, info_regexes) for info_input in df_info.description]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(dict_series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [extract_first_pred(predictions) for predictions in df[\"predictions\"]]\n",
    "df[\"first_pred\"] = [prediction[0] for prediction in predictions]\n",
    "df[\"second_pred\"] = [prediction[0] for prediction in predictions]\n",
    "df[\"first_proba\"] = [prediction[0] for prediction in predictions]\n",
    "df[\"second_proba\"] = [prediction[0] for prediction in predictions]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"comparison.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df.RAW.str.contains(\"oeuvre\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.RAW.iloc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.RAW.replace(\n",
    "    to_replace=r\"(\\s|^)([a-z]{1})(?:\\s|$)\", value=r'\\1', regex=True\n",
    ").iloc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.RAW.replace(\n",
    "    to_replace=r\"\\b([a-z]{1})\\b\", value=' ', regex=True\n",
    ").iloc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import unidecode\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords as ntlk_stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from enum import Enum\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "HEADER_LEN = 58\n",
    "EVENT_LEN = 41\n",
    "\n",
    "\n",
    "class EventType(Enum):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    ID = \"s.i.AbstractBatchCodificationServiceImpl\"\n",
    "    INFO = \"r.b.j.c.s.i.BatchCodificationServiceImpl\"\n",
    "    RAW_INPUT = \"stractLiasse1ToLiasseVarInteretProcessor\"\n",
    "\n",
    "\n",
    "def extract_log_info(f):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        f (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    event_types = []\n",
    "    descriptions = []\n",
    "    for line in f:\n",
    "        line_without_timestamp = line[HEADER_LEN:]\n",
    "        if not line_without_timestamp:\n",
    "            continue\n",
    "        event_types.append(line_without_timestamp[:EVENT_LEN].rstrip())\n",
    "        descriptions.append(line_without_timestamp[EVENT_LEN + 2:])\n",
    "    return pd.DataFrame(\n",
    "        list(zip(event_types, descriptions)),\n",
    "        columns=['event_type', 'description']\n",
    "    )\n",
    "\n",
    "\n",
    "def parse_raw_input(raw_input, fields, regexes):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        raw_input (_type_): _description_\n",
    "        fields (_type_): _description_\n",
    "        regexes (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    raw_input_dict = {}\n",
    "    for field, regex in zip(fields, regexes):\n",
    "        matches = regex.search(raw_input)\n",
    "        if matches.group(1) is not None:\n",
    "            raw_input_dict[field] = matches.group(1).strip('\"')\n",
    "        else:\n",
    "            raw_input_dict[field] = matches.group(2)\n",
    "    return raw_input_dict\n",
    "\n",
    "\n",
    "def extract_first_pred(predictions):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        predictions (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    regex = re.compile(r'proposé = ([^;]*) ;.*associée = ([^;]*)\\].*proposé = ([^;]*) ;.*associée = ([^;]*)\\]')\n",
    "    matches = regex.search(predictions)\n",
    "    first_code = matches.group(1)\n",
    "    second_code = matches.group(3)\n",
    "    first_proba = matches.group(2)\n",
    "    second_proba = matches.group(4)\n",
    "    return (first_code, second_code, float(first_proba), float(second_proba))\n",
    "\n",
    "\n",
    "def clean_lib(df, text_feature):\n",
    "        \"\"\"\n",
    "        Cleans a text feature for pd.DataFrame `df` at index idx.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): DataFrame.\n",
    "            text_feature (str): Name of the text feature.\n",
    "\n",
    "        Returns:\n",
    "            df (pd.DataFrame): DataFrame.\n",
    "        \"\"\"\n",
    "#        Libellé vide de sens fournit par Christine\n",
    "#        LibVideSens = r\"\\bidem\\b|\\bvoir ci dessous\\b|\\[vide\\]|\\bundefined\\b|\\bpas d objet\\b|\\(voir ci dessus\\)|\\(voir extrait siege social\\/etablissement principal\\)|\\bcf activite principale\\b|\\bcf activite principale et objet\\b|\\bcf activites de l entreprise\\b|\\bcf activites principales de l entreprise\\b|\\bcf actvites principales\\b|\\bcf k bis\\b|\\bcf le principales activites de l  entreprise\\b|\\bcf le sprincipale activites de l  entreprise\\b|\\bcf le sprincipales activites de l  entreprise\\b|\\bcf les activites principales de l  entreprise\\b|\\bcf les ppales activites de l  entreprise\\b|\\bcf les ppales activites de la ste\\b|\\bcf les principale activites de l  entreprise\\b|\\bcf les principales activites\\b|\\bcf les principales activites de l  entreprise\\b|\\bcf les principales activites de l  entreprises\\b|\\bcf les principales activites ppales de l  entreprise\\b|\\bcf les principales activtes de l  entreprise\\b|\\bcf les principales acttivites de l  entreprise\\b|\\bcf les prinipales activites de l  entreprise\\b|\\bcf lesprincipales activites de l  entreprise\\b|\\bcf objet\\b|\\bcf obs\\b|\\bcf principales activite de l  entreprise\\b|\\bcf principales activites de l  entreprise\\b|cf rubrique \\\"principales activites de l entreprise\\\" idem|cf rubrique n2 ci dessus \\(743b\\)|\\bcf supra\\b|\\bcf ci  dessus\\b|\\bcommerce de detail, idem case 2\\b|\\bextension a: voir ci dessus\\b|\\bid\\b|\\bid principales activites\\b|\\bid principales activites de l  entreprise\\b|\\bidem ci dessus\\b|idem \\( voir principales activites\\)|\\bidem  dessus\\b|\\bidem 1ere page\\b|\\bidem a principales activites de l  entreprise\\b|\\bidem activiet eprincipale\\b|\\bidem activite\\b|\\bidem activite 1ere page\\b|\\bidem activite ci  dessus\\b|\\bidem activite de l  entreprise\\b|\\bidem activite enoncee ci  dessus\\b|\\bidem activite entreprise\\b|\\bidem activite generales\\b|\\bidem activite premiere page\\b|\\bidem activite principale\\b|\\bidem activite princippale\\b|\\bidem activite prinicpale\\b|\\bidem activite sur 1ere page\\b|\\bidem activites ci dessus\\b|\\bidem activites declarees au siege et principal\\b|\\bidem activites enoncees ci dessus\\b|\\bidem activites entreprise\\b|\\bidem activites principales\\b|\\bidem activites principales de l entreprise\\b|\\bidem activites siege\\b|\\bidem activte principale\\b|\\bidem activtie 1ere page\\b|\\bidem au siege\\b|\\bidem au siege social\\b|\\bidem aux principales actiivtes\\b|\\bidem aux principales activites\\b|\\bidem case 13\\b|\\bidem ci dessous\\b|\\bidem ci dessus enoncee\\b|\\bidem cidessus\\b|\\bidem objet\\b|\\bidem premiere page\\b|\\bidem pricincipales activites de l entreprise\\b|\\bidem pricipales activites\\b|\\bidem principale activite\\b|\\bidem principales activite de l entreprise\\b|\\bidem principales activite de l entreprises\\b|\\bidem principales activite l entreprise\\b|\\bidem principales activites\\b|\\bidem principales activites citees ci dessus\\b|\\bidem principales activites de l entreprises\\b|idem principales activites de l entreprise\\(objet\\)|\\bidem principales activites et objet social\\b|\\bidem principales activitse de l entreprise\\b|\\bidem que celle decrite plus haut\\b|\\bidem que ci dessus\\b|\\bidem que l activite decrite plus haut\\b|\\bidem que les activites principales\\b|\\bidem que les activites principales ci dessus\\b|\\bidem que les activitges principales\\b|\\bidem que les principales activites\\b|\\bidem que les principales activites de l entreprise\\b|\\bidem que pour le siege\\b|\\bidem rubrique principales activites de l entreprise\\b|\\bidem siege\\b|idem siege \\+ voir observation|\\bidem siege et ets principal\\b|\\bidem siege social\\b|idem siege, \\(\\+ articles americains\\)|\\bidem societe\\b|\\bidem voir activite principale\\b|\\bidem voir ci dessus\\b|\\bidentique a l objet social indique en case 2 de l imprime m2\\b|\\bidm ci dessus\\b|\\bnon indiquee\\b|\\bnon precise\\b|\\bnon precisee\\b|\\bnon precisees\\b|\\bvoir 1ere page\\b|\\bvoir activite ci dessus\\b|\\bvoir activite principale\\b|\\bvoir activite principale ci dessus\\b|\\bvoir activites principales\\b|\\bvoir cidessus\\b|\\bvoir idem ci dessus\\b|\\bvoir objet social\\b|\\bvoir page 1\\b|\\bvoir page precedente\\b|\\bvoir plus haut\\b|\\bvoir princiale activite\\b|\\bvoir princiales activites\\b|\\bvoir princiapales activites\\b|\\bvoir princiaples activites\\b|\\bvoir principale activite\\b|\\bvoir principales activites\\b|\\bvoir principales activites de l entreprise\\b|\\bvoir principales actvites\\b|\\bvoir principalesactivites\\b|\\bvoir principles activites\\b|\\bvoir rubrique principales activites de l entreprise\\b|\\bvoir sur la 1ere page\\b|\\bvoir dessus\\b|voir: \\\"principales activite de l entreprise\\\"|voir: \\\"principales activites de l entreprises\\\"|voir: \\\"principales activites de l entrprise\\\"|voir: \\\"principales activites en entreprise\\\"|\\bconforme au kbis\\b|\\bsans changement\\b|\\bsans activite\\b|\\bsans acitivite\\b|\\bactivite inchangee\\b|\\bactivites inchangees\\b|\\bsiege social\\b|\\ba definir\\b|\\ba preciser\\b|\\bci dessus\\b|\\bci desus\\b|\\bci desssus\\b|\\bvoir activit principale\\b|\\bidem extrait kbis\\b|\\bn a plus a etre mentionne sur l extrait decret\\b|\\bcf statuts\\b|\\bactivite principale case\\b|\\bactivites principales case\\b|\\bactivite principale\\b|\\bactivites principales\\b|\\bvoir case\\b|\\baucun changement\\b|\\bsans modification\\b|\\bactivite non modifiee\\b|\\bactivite identique\\b|\\bpas de changement\\b|\\bcode\\b|\\bape\\b|\\bnaf\\b|\\binchangee\\b|\\binchnagee\\b|\\bkbis\\b|\\bk bis\\b|\\binchangees\\b|\\bnp\\b|\\binchange\\b|\\bnc\\b|\\bxx\\b|\\bxxx\\b|\\binconnue\\b|\\binconnu\\b|\\bvoir\\b|\\bannexe\\b|\\bmo\\b|\\biem\\b|\\binchanges\\b|\\bactivite demeure\\b|\\bactivite inchangée\\b|\\bcase precedente\\b|\\bidem cadre precedent\\b|\\bactivite demeure\\b|\\bactivite inchangée\\b|\\bnon renseignee\\b|\\bneant\\b|\\bnon renseigne\\b\"\n",
    "\n",
    "        # On définit une regex de mots à supprimer du jeu de données\n",
    "        Word2remove = r\"\\bcode\\b|\\bcadre\\b|\\bape\\b|\\bape[a-z]{1}\\b|\\bnaf\\b|\\binchangee\\b|\\binchnagee\\b|\\bkbis\\b|\\bk bis\\b|\\binchangees\\b|\\bnp\\b|\\binchange\\b|\\bnc\\b|\\bidem\\b|\\bxx\\b|\\bxxx\\b|\\baa\\b|\\baaa\\b|\\bidem cadre precedent\\b|\\bidem case\\b|\\binchanges\\b|\\bmo\\b|\\biem\\b|\\bci dessus\\b|\\bet\\b\"\n",
    "\n",
    "        # On harmonise l'encodage (principalement suppression accents)\n",
    "        df[text_feature] = df[text_feature].map(unidecode.unidecode)\n",
    "\n",
    "        # On passe tout en minuscule\n",
    "        df[text_feature] = df[text_feature].map(str.lower)\n",
    "\n",
    "        # On supprime les libellés vide de sens (DOIT ETRE FAIT EN AMONT DU MODELE EN JAVA)\n",
    "        #df[text_feature] = df[text_feature].replace(\n",
    "        #    to_replace=LibVideSens, value=\"\", regex=True\n",
    "        #)\n",
    "\n",
    "        # supprime hyphen pour les mots comme e-commerce\n",
    "        df[text_feature] = df[text_feature].replace(\n",
    "            to_replace=r\"e-\", value=\"e\", regex=True\n",
    "        )\n",
    "\n",
    "        # accole le e pour les mots comme e-commerce\n",
    "        df[text_feature] = df[text_feature].replace(\n",
    "            to_replace=r\"\\be\\s\", value=\" e\", regex=True\n",
    "        )\n",
    "\n",
    "        # On supprime toutes les ponctuations\n",
    "        df[text_feature] = df[text_feature].replace(\n",
    "            to_replace=r\"[^\\w\\s]+\", value=\" \", regex=True\n",
    "        )\n",
    "\n",
    "        # On supprime certains mots sans sens (DOIT ETRE FAIT DANS LE PREPROCESSING EN JAVA)\n",
    "        df[text_feature] = df[text_feature].replace(\n",
    "            to_replace=Word2remove, value=\"\", regex=True\n",
    "        )\n",
    "\n",
    "        # On supprime les mots d'une seule lettre\n",
    "        df[text_feature] = df[text_feature].apply(\n",
    "            lambda x: ' '.join([w for w in x.split() if len(w) > 1])\n",
    "        )\n",
    "\n",
    "        # On supprime tous les chiffres\n",
    "        df[text_feature] = df[text_feature].replace(\n",
    "            to_replace=r\"[\\d+]\", value=\" \", regex=True\n",
    "        )\n",
    "\n",
    "        # On supprime les mots d'une seule lettre\n",
    "        df[text_feature] = df[text_feature].apply(\n",
    "            lambda x: ' '.join([w for w in x.split() if len(w) > 1])\n",
    "        )\n",
    "\n",
    "        # On supprime les multiple space\n",
    "        df[text_feature] = df[text_feature].replace(r\"\\s\\s+\", \" \", regex=True)\n",
    "\n",
    "        # On strip les libellés\n",
    "        df[text_feature] = df[text_feature].str.strip()\n",
    "\n",
    "        # On remplace les empty string par des NaN\n",
    "        df[text_feature] = df[text_feature].replace(r\"^\\s*$\", np.nan, regex=True)\n",
    "\n",
    "        # On supprime les NaN\n",
    "        # df = df.dropna(subset=[text_feature])\n",
    "        df[text_feature] =df[text_feature].fillna(value=\"NaN\")\n",
    "\n",
    "        # On tokenize tous les libellés\n",
    "        libs_token = [lib.split() for lib in df[text_feature].to_list()]\n",
    "\n",
    "        # Pour chaque libellé on supprime les stopword et on racinise les mots\n",
    "        libs_token = [\n",
    "            [\n",
    "                stemmer.stem(word)\n",
    "                for word in libs_token[i]\n",
    "                if word not in stopwords\n",
    "            ]\n",
    "            for i in range(len(libs_token))\n",
    "        ]\n",
    "\n",
    "        # On supprime les mots duppliqués dans un même libellé\n",
    "        libs_token = [\n",
    "            sorted(set(libs_token[i]), key=libs_token[i].index)\n",
    "            for i in range(len(libs_token))\n",
    "        ]\n",
    "\n",
    "        df[text_feature] = [\n",
    "            \" \".join(libs_token[i]) for i in range(len(libs_token))\n",
    "        ]\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "RAW_INPUT_FIELDS = [\n",
    "    \"norme\",\n",
    "    \"siren\",\n",
    "    \"nic\",\n",
    "    \"liasseType\",\n",
    "    \"categorieJuridique\",\n",
    "    \"domas\",\n",
    "    \"ssdom\",\n",
    "    \"domaineAssoc\",\n",
    "    \"ssDomaineAssoc\",\n",
    "    \"libelleActivitePrincipaleEtablissement\",\n",
    "    \"sedentarite\",\n",
    "    \"natureActivites\",\n",
    "    \"surface\",\n",
    "    \"lieuExercice\",\n",
    "    \"presenceSalaries\"\n",
    "]\n",
    "RAW_INPUT_REGEXES = [\n",
    "    re.compile(r'{}'.format(field + '=([^,]*)[,\\]]'))\n",
    "    for field in RAW_INPUT_FIELDS\n",
    "]\n",
    "INFO_FIELDS = [\n",
    "    \"natureActivites\",\n",
    "    \"liasseType\",\n",
    "    \"evenementType\",\n",
    "    \"surface\",\n",
    "    \"libelleNettoye\",\n",
    "    \"predictions\",\n",
    "    \"bilan\"\n",
    "]\n",
    "INFO_REGEXES = [\n",
    "    re.compile(r'{}'.format(field + '=([^,]*),'))\n",
    "    for field in INFO_FIELDS\n",
    "]\n",
    "INFO_FIELDS.append(\"fasttextVersion\")\n",
    "INFO_REGEXES.append(re.compile(r'fasttextVersion=([^,]*)\\]'))\n",
    "INFO_FIELDS.append(\"libelleActivite\")\n",
    "INFO_REGEXES.append(re.compile(r'libelleActivite=(\\\"[^\\\"]*\\\")?([^,]*),'))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with open(\"../data/api_log.log\") as f:\n",
    "        df = extract_log_info(f)\n",
    "\n",
    "    df_ids = df[df.event_type == EventType.ID.value]\n",
    "    df_info = df[df.event_type == EventType.INFO.value]\n",
    "    df_raw_input = df[df.event_type == EventType.RAW_INPUT.value]\n",
    "    df_raw_input = df_raw_input[\n",
    "        df_raw_input.description.str.startswith(\"LiasseVarInteretCodification\")\n",
    "    ]\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        [\n",
    "            parse_raw_input(info_input, INFO_FIELDS, INFO_REGEXES)\n",
    "            for info_input in df_info.description\n",
    "            if not info_input.__contains__('\"\"')\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    predictions = [\n",
    "        extract_first_pred(predictions)\n",
    "        for predictions in df[\"predictions\"]\n",
    "    ]\n",
    "    df[\"first_pred\"] = [prediction[0] for prediction in predictions]\n",
    "    df[\"second_pred\"] = [prediction[1] for prediction in predictions]\n",
    "    df[\"first_proba\"] = [prediction[2] for prediction in predictions]\n",
    "    df[\"second_proba\"] = [prediction[3] for prediction in predictions]\n",
    "\n",
    "    stemmer = SnowballStemmer(language=\"french\")\n",
    "    stopwords = tuple(ntlk_stopwords.words(\"french\")) + tuple(string.ascii_lowercase)\n",
    "\n",
    "    dff = df.copy()\n",
    "    dff[\"libelleActivite\"] = df[\"libelleActivite\"].fillna(value=\"NaN\")\n",
    "    df_prepro = clean_lib(dff, \"libelleActivite\")\n",
    "    lib_raw = df.libelleActivite.to_list()\n",
    "    lib_clean_PY = df_prepro.libelleActivite.to_list()\n",
    "    lib_clean_JAVA = df.libelleNettoye.apply(lambda x : x.split(\" AUTO\")[0]).to_list()\n",
    "    compare_libs = pd.DataFrame({\"RAW\" : lib_raw, \"PYTHON\" : lib_clean_PY, \"JAVA\" : lib_clean_JAVA})\n",
    "    compare_libs[\"CHECK\"] = compare_libs.PYTHON ==  compare_libs.JAVA\n",
    "    compare_libs.to_csv(\"comparison.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = compare_libs[~compare_libs[\"CHECK\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.to_csv(\"false.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Prepro mots vide de sens\n",
    "2) ```\"œ\"``` pas décodé de la même manière\n",
    "3) ```\"€\"``` pas décodé de la même manière\n",
    "4) ```\"Yeti\"``` pas racinisé de la même manière\n",
    "5) ```\"Terassemment\"``` pas racinisé de la même manière"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "model = fasttext.load_model(\"../models/model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.predict(df[compare_libs.CHECK].libelleNettoye.to_list(), k=3)\n",
    "\n",
    "first_pred = [res[0][i][0].replace(\"__label__\", \"\") for i in range(len(res[0]))]\n",
    "second_pred = [res[0][i][1].replace(\"__label__\", \"\") for i in range(len(res[0]))]\n",
    "trois_pred = [res[0][i][2].replace(\"__label__\", \"\") for i in range(len(res[0]))]\n",
    "first_proba = [res[1][i][0] for i in range(len(res[1]))]\n",
    "second_proba = [res[1][i][1] for i in range(len(res[1]))]\n",
    "trois_proba = [res[1][i][2] for i in range(len(res[1]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib_clean = df[compare_libs.CHECK].libelleNettoye.apply(lambda x : x.split(\" AUTO\")[0]).to_list()\n",
    "\n",
    "df_compare = pd.DataFrame({\n",
    "    \"Lib\" : df[compare_libs.CHECK].libelleNettoye, \n",
    "    \"pred_1_PY\" : first_pred, \n",
    "    \"pred_1_JAVA\" : df[compare_libs.CHECK].first_pred,\n",
    "    \"pred_2_PY\" : second_pred, \n",
    "    \"pred_2_JAVA\" : df[compare_libs.CHECK].second_pred,\n",
    "    \"prob_1_PY\" : first_proba, \n",
    "    \"prob_1_JAVA\" : df[compare_libs.CHECK].first_proba,\n",
    "    \"prob_2_PY\" : second_proba, \n",
    "    \"prob_2_JAVA\" : df[compare_libs.CHECK].second_proba,\n",
    "    \"pred_3_PY\" : trois_pred, \n",
    "    \"prob_3_PY\" : trois_proba, \n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lib</th>\n",
       "      <th>pred_1_PY</th>\n",
       "      <th>pred_1_JAVA</th>\n",
       "      <th>pred_2_PY</th>\n",
       "      <th>pred_2_JAVA</th>\n",
       "      <th>prob_1_PY</th>\n",
       "      <th>prob_1_JAVA</th>\n",
       "      <th>prob_2_PY</th>\n",
       "      <th>prob_2_JAVA</th>\n",
       "      <th>pred_3_PY</th>\n",
       "      <th>prob_3_PY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>coaching sportif AUTO_X NAT_SICORE_NaN SURF_Na...</td>\n",
       "      <td>8551Z</td>\n",
       "      <td>8551Z</td>\n",
       "      <td>9609Z</td>\n",
       "      <td>9609Z</td>\n",
       "      <td>0.994950</td>\n",
       "      <td>0.994950</td>\n",
       "      <td>0.002642</td>\n",
       "      <td>0.002642</td>\n",
       "      <td>8559B</td>\n",
       "      <td>0.000814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>realis dessin anim AUTO_X NAT_SICORE_NaN SURF_...</td>\n",
       "      <td>9003A</td>\n",
       "      <td>9003A</td>\n",
       "      <td>1813Z</td>\n",
       "      <td>1813Z</td>\n",
       "      <td>0.615098</td>\n",
       "      <td>0.615098</td>\n",
       "      <td>0.334599</td>\n",
       "      <td>0.334599</td>\n",
       "      <td>5911A</td>\n",
       "      <td>0.152042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>electricien electricit general AUTO_Z NAT_SICO...</td>\n",
       "      <td>4321A</td>\n",
       "      <td>4321A</td>\n",
       "      <td>4321B</td>\n",
       "      <td>4321B</td>\n",
       "      <td>1.000010</td>\n",
       "      <td>1.000010</td>\n",
       "      <td>0.000893</td>\n",
       "      <td>0.000893</td>\n",
       "      <td>9820Z</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>prestat servic assist ressort britann tach adm...</td>\n",
       "      <td>6831Z</td>\n",
       "      <td>6831Z</td>\n",
       "      <td>8219Z</td>\n",
       "      <td>8219Z</td>\n",
       "      <td>0.148057</td>\n",
       "      <td>0.148057</td>\n",
       "      <td>0.140346</td>\n",
       "      <td>0.140346</td>\n",
       "      <td>8211Z</td>\n",
       "      <td>0.095359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>agent commercial mandatair immobili AUTO_R NAT...</td>\n",
       "      <td>6831Z</td>\n",
       "      <td>6831Z</td>\n",
       "      <td>4619B</td>\n",
       "      <td>4619B</td>\n",
       "      <td>1.000010</td>\n",
       "      <td>1.000010</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>9820Z</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32859</th>\n",
       "      <td>realis seanc hypnos AUTO_C NAT_SICORE_99 SURF_...</td>\n",
       "      <td>9609Z</td>\n",
       "      <td>9609Z</td>\n",
       "      <td>8690F</td>\n",
       "      <td>8690F</td>\n",
       "      <td>0.971574</td>\n",
       "      <td>0.971574</td>\n",
       "      <td>0.050341</td>\n",
       "      <td>0.050341</td>\n",
       "      <td>4771Z</td>\n",
       "      <td>0.003604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32860</th>\n",
       "      <td>exploit boutiqu ecommerc recour acte commerc A...</td>\n",
       "      <td>4791A</td>\n",
       "      <td>4791A</td>\n",
       "      <td>4791B</td>\n",
       "      <td>4791B</td>\n",
       "      <td>0.476590</td>\n",
       "      <td>0.476590</td>\n",
       "      <td>0.055015</td>\n",
       "      <td>0.055015</td>\n",
       "      <td>6820A</td>\n",
       "      <td>0.006300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32861</th>\n",
       "      <td>preprat vent plat cuisin emport AUTO_C NAT_SIC...</td>\n",
       "      <td>5610C</td>\n",
       "      <td>5610C</td>\n",
       "      <td>4724Z</td>\n",
       "      <td>4724Z</td>\n",
       "      <td>0.314061</td>\n",
       "      <td>0.314061</td>\n",
       "      <td>0.013233</td>\n",
       "      <td>0.013233</td>\n",
       "      <td>5621Z</td>\n",
       "      <td>0.004342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32862</th>\n",
       "      <td>anim ateli stag spectacl improvis theatral clo...</td>\n",
       "      <td>9001Z</td>\n",
       "      <td>9001Z</td>\n",
       "      <td>8552Z</td>\n",
       "      <td>8552Z</td>\n",
       "      <td>0.999474</td>\n",
       "      <td>0.999474</td>\n",
       "      <td>0.766304</td>\n",
       "      <td>0.766304</td>\n",
       "      <td>9004Z</td>\n",
       "      <td>0.035155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32863</th>\n",
       "      <td>petit pech AUTO_X NAT_SICORE_NaN SURF_NaN EVT_...</td>\n",
       "      <td>0311Z</td>\n",
       "      <td>0311Z</td>\n",
       "      <td>0312Z</td>\n",
       "      <td>0312Z</td>\n",
       "      <td>0.679189</td>\n",
       "      <td>0.679189</td>\n",
       "      <td>0.029322</td>\n",
       "      <td>0.029322</td>\n",
       "      <td>8551Z</td>\n",
       "      <td>0.011697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32853 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Lib pred_1_PY  \\\n",
       "0      coaching sportif AUTO_X NAT_SICORE_NaN SURF_Na...     8551Z   \n",
       "1      realis dessin anim AUTO_X NAT_SICORE_NaN SURF_...     9003A   \n",
       "2      electricien electricit general AUTO_Z NAT_SICO...     4321A   \n",
       "3      prestat servic assist ressort britann tach adm...     6831Z   \n",
       "4      agent commercial mandatair immobili AUTO_R NAT...     6831Z   \n",
       "...                                                  ...       ...   \n",
       "32859  realis seanc hypnos AUTO_C NAT_SICORE_99 SURF_...     9609Z   \n",
       "32860  exploit boutiqu ecommerc recour acte commerc A...     4791A   \n",
       "32861  preprat vent plat cuisin emport AUTO_C NAT_SIC...     5610C   \n",
       "32862  anim ateli stag spectacl improvis theatral clo...     9001Z   \n",
       "32863  petit pech AUTO_X NAT_SICORE_NaN SURF_NaN EVT_...     0311Z   \n",
       "\n",
       "      pred_1_JAVA pred_2_PY pred_2_JAVA  prob_1_PY  prob_1_JAVA  prob_2_PY  \\\n",
       "0           8551Z     9609Z       9609Z   0.994950     0.994950   0.002642   \n",
       "1           9003A     1813Z       1813Z   0.615098     0.615098   0.334599   \n",
       "2           4321A     4321B       4321B   1.000010     1.000010   0.000893   \n",
       "3           6831Z     8219Z       8219Z   0.148057     0.148057   0.140346   \n",
       "4           6831Z     4619B       4619B   1.000010     1.000010   0.000367   \n",
       "...           ...       ...         ...        ...          ...        ...   \n",
       "32859       9609Z     8690F       8690F   0.971574     0.971574   0.050341   \n",
       "32860       4791A     4791B       4791B   0.476590     0.476590   0.055015   \n",
       "32861       5610C     4724Z       4724Z   0.314061     0.314061   0.013233   \n",
       "32862       9001Z     8552Z       8552Z   0.999474     0.999474   0.766304   \n",
       "32863       0311Z     0312Z       0312Z   0.679189     0.679189   0.029322   \n",
       "\n",
       "       prob_2_JAVA pred_3_PY  prob_3_PY  \n",
       "0         0.002642     8559B   0.000814  \n",
       "1         0.334599     5911A   0.152042  \n",
       "2         0.000893     9820Z   0.000010  \n",
       "3         0.140346     8211Z   0.095359  \n",
       "4         0.000367     9820Z   0.000010  \n",
       "...            ...       ...        ...  \n",
       "32859     0.050341     4771Z   0.003604  \n",
       "32860     0.055015     6820A   0.006300  \n",
       "32861     0.013233     5621Z   0.004342  \n",
       "32862     0.766304     9004Z   0.035155  \n",
       "32863     0.029322     8551Z   0.011697  \n",
       "\n",
       "[32853 rows x 11 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = model.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([x.split(\"__label__\")[1] for x in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = df_compare[(df_compare.pred_1_PY != df_compare.pred_1_JAVA)].pred_1_PY.to_list()\n",
    "pred2 = df_compare[(df_compare.pred_1_PY != df_compare.pred_1_JAVA)].pred_2_PY.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49, 11)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_compare[(df_compare.pred_1_PY != df_compare.pred_1_JAVA)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49, 11)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_compare[(df_compare.pred_1_PY != df_compare.pred_1_JAVA)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 11)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_compare[(df_compare.pred_2_PY != df_compare.pred_2_JAVA) & (df_compare.pred_1_PY == df_compare.pred_1_JAVA)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 11)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_compare[(abs(df_compare.prob_1_PY - df_compare.prob_1_JAVA)> 0.00001)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32853, 11)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_compare.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3fa046f995eb80ac40c0869a1f9df46519f4ada8b8c395ef25dd1aa1a1a2fc63"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
