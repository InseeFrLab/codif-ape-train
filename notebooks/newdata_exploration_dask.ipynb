{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8549431c-6a29-4f96-a18d-4d123c8dd243",
   "metadata": {},
   "source": [
    "# Exploration des données de Sirene"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4e4578",
   "metadata": {},
   "source": [
    "## Importation des différents packages nécessaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9ee43e-b8d9-4c5f-8b60-6512c958a173",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import random\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import fasttext\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fde385",
   "metadata": {},
   "source": [
    "## Importation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da137d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DBRaw = dd.read_parquet('../data/extraction_sirene_20220510.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb18498",
   "metadata": {},
   "source": [
    "Temporaire : On restreint les données à 1% de la base initiales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d42b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DBRaw = DBRaw.sample(frac= 0.01, random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ebd953",
   "metadata": {},
   "source": [
    "On transforme les valeurs manquantes en NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f109d898",
   "metadata": {},
   "outputs": [],
   "source": [
    "DBRaw = DBRaw.fillna(value=np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbec49e",
   "metadata": {},
   "source": [
    "On garde seulement les variables potentiellement intéressantes : \n",
    "- ``APE_SICORE :`` Code APE (Activité Principale Exercée) retenu lors du traitement de codification (soit Sicore soit gestionnaire) ;\n",
    "- ``NAT_SICORE :`` Nature de l'activité de l'entreprise ;\n",
    "- ``SED_SICORE :`` Sédentarité de l'entreprise ;\n",
    "- ``EVT_SICORE :`` Sédentarité de l'entreprise ;\n",
    "- ``LIB_SICORE :`` Sédentarité de l'entreprise ;\n",
    "- ``DATE :`` Sédentarité de l'entreprise ;\n",
    "- ``AUTO :`` Type de liasse extrait de la base brute Sirène ;\n",
    "- ``SURF :`` Surface en $m^2$ de l'établissement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550efe05",
   "metadata": {},
   "outputs": [],
   "source": [
    "Var2Keep = [\"APE_SICORE\",\"LIB_SICORE\",\"AUTO\",\"DATE\",\"NAT_SICORE\",\"SED_SICORE\",\"EVT_SICORE\",\"SURF\"]\n",
    "DB = DBRaw[Var2Keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6338f6ef",
   "metadata": {},
   "source": [
    "On supprime les liasses où une valeur est manquante pour l'une de ces deux variables (6.77% de la base). Il s'agit principalement du code APE donc il n'est pas nécessaire de l'imputer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921dbd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB = DB.dropna(subset=['APE_SICORE'])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ed07a1",
   "metadata": {},
   "source": [
    "On a finalement 10.8 millions de liasses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252a27b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB.shape[0].compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7a6ff3",
   "metadata": {},
   "source": [
    "## I- Modèle 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94485c9",
   "metadata": {},
   "source": [
    "On estime un modèle FastText standard en utilisant seulement les libellés comme features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b69513",
   "metadata": {},
   "source": [
    "### 1) Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e191f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB1 = DB[[\"APE_SICORE\",\"LIB_SICORE\"]]\n",
    "DB1 = DB1.dropna(subset=['LIB_SICORE'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b2a6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_ = set(stopwords.words('french') + ['a'])\n",
    "def CleanLib(lib):\n",
    "    # On supprime toutes les ponctuations\n",
    "    lib = lib.translate(str.maketrans(string.punctuation, ' ' * len(string.punctuation)))\n",
    "    # On supprime tous les chiffres\n",
    "    lib = lib.translate(str.maketrans(string.digits, ' ' * len(string.digits)))\n",
    "\n",
    "    # On supprime les stopwords et on renvoie les mots en majuscule\n",
    "    return \" \".join([x.lower() for x in lib.split() if x.lower() not in stopwords_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d247a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB1[\"LIB_CLEAN\"] = DB1[\"LIB_SICORE\"].apply(lambda x: CleanLib(x), meta=pd.Series(dtype='str', name='LIB_CLEAN'))\n",
    "df = DB1.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3313f31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fb0e9e",
   "metadata": {},
   "source": [
    "### 2) Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8268132b",
   "metadata": {},
   "source": [
    "On mélange de manière aléatoires les index puis on les divise en 2 groupes selon un certain pourcentage (ici 80% et 20%)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4094786a",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123456)\n",
    "Idx = random.sample(df.index.values.tolist(), df.shape[0])\n",
    "Groups = np.split(Idx, [int(len(Idx)*0.8)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693b4426",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/train_text.txt\", 'w') as f:\n",
    "    for idx in range(len(Groups[0])):\n",
    "        aLine = \"__label__{} {}\".format(df.at[Groups[0][idx],\"APE_SICORE\"], df.at[Groups[0][idx],\"LIB_CLEAN\"])\n",
    "        f.write(\"%s\\n\" % aLine)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d5a745",
   "metadata": {},
   "source": [
    "### 3) Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f5fae1",
   "metadata": {},
   "source": [
    "On définit plusieurs options pour le modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6994b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_fasttext={\"dim\": 150,\n",
    "\"lr\": 0.2,\n",
    "\"epoch\": 80,\n",
    "\"wordNgrams\": 3,\n",
    "\"minn\": 3,\n",
    "\"maxn\": 4,\n",
    "\"minCount\": 3,\n",
    "\"bucket\": 3000000,\n",
    "\"thread\": 25,\n",
    "\"loss\": 'ova',\n",
    "\"label_prefix\": '__label__'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d9f244",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = fasttext.train_supervised(input=\"../data/train_text.txt\", **config_fasttext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94c070b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TypeData = [\"Train\", \"Test\"]\n",
    "dico_lib= { TypeData[i] : {Groups[i][idx] : {\"TrueValue\" : df.at[Groups[1][idx],\"APE_SICORE\"],\n",
    "                                                \"Libelle\" : df.at[Groups[1][idx],\"LIB_CLEAN\"]} \n",
    "                                                for idx in range(len(Groups[1]))\n",
    "                            } for i in range(len(TypeData))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd39d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred(lib, mod):\n",
    "    out = mod.predict(lib)\n",
    "    pred = out[0][0].replace(\"__label__\",\"\")\n",
    "    prob = out[1][0]\n",
    "    return [pred, prob]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a1c3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[['C', 'D']] = df_test['LIB_CLEAN'].apply(lambda x: get_pred(x, model1)).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa2ce0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98521cfa",
   "metadata": {},
   "source": [
    "Accuracy of the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f78aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.loc[Groups[0], :]\n",
    "df_train[['PREDICTION', 'PROBA']] = df_train['LIB_CLEAN'].apply(lambda x: get_pred(x, model1)).to_list()\n",
    "df_train['GoodPREDICTION'] = df_train['APE_SICORE'] == df_train['PREDICTION']\n",
    "sum(df_train['GoodPREDICTION'])/df_train.shape[0] * 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf9a3e5",
   "metadata": {},
   "source": [
    "Accuracy of the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c94be99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.loc[Groups[1], :]\n",
    "df_test[['PREDICTION', 'PROBA']] = df_test['LIB_CLEAN'].apply(lambda x: get_pred(x, model1)).to_list()\n",
    "df_test['GoodPREDICTION'] = df_test['APE_SICORE'] == df_test['PREDICTION']\n",
    "sum(df_test['GoodPREDICTION'])/df_test.shape[0] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacf039b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_naf =  pd.read_csv(r\"../data/naf_extended.csv\",sep=\",\",encoding=\"utf-8\",dtype=str)\n",
    "df_naf[\"NIV5\"] = df_naf[\"NIV5\"].str.replace(\".\",\"\")        \n",
    "df_naf.set_index(\"NIV5\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f8994b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_naf = df_naf[[\"NIV1\",\"NIV2\", \"NIV3\", \"NIV4\", \"LIB_NIV5\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a40ad1",
   "metadata": {},
   "source": [
    "On regarde la precision le rappel et le F1 pour les différentes classes désaggrégées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0585dcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_naf = df_naf.join(df_train.groupby(['APE_SICORE']).size().rename(\"Size_TRAIN\").to_frame())\n",
    "df_naf = df_naf.join(df_test.groupby(['APE_SICORE']).size().rename(\"Size_TEST\").to_frame())\n",
    "df_naf = df_naf.join(df_test.groupby(['APE_SICORE']).mean('GoodPREDICTION').rename(columns={\"GoodPREDICTION\":\"Recall_TEST\"}))\n",
    "df_naf = df_naf.join(df_test.groupby(['PREDICTION']).mean('GoodPREDICTION').rename(columns={\"GoodPREDICTION\":\"Precision_TEST\"}))\n",
    "df_naf = df_naf.join(2 * 1/(1/df_naf[\"Precision_TEST\"] + 1/df_naf[\"Recall_TEST\"]).rename(\"F1_TEST\").to_frame())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799478a0",
   "metadata": {},
   "source": [
    "On fait la même chose au niveau moins aggrégé"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
