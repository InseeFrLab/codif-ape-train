{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8549431c-6a29-4f96-a18d-4d123c8dd243",
   "metadata": {},
   "source": [
    "# Exploration des données de Sirene"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4e4578",
   "metadata": {},
   "source": [
    "## Importation des différents packages nécessaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "aa9ee43e-b8d9-4c5f-8b60-6512c958a173",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/coder/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "import string\n",
    "import swifter\n",
    "from nltk.corpus import stopwords\n",
    "import fasttext\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fde385",
   "metadata": {},
   "source": [
    "## Importation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "8da137d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DBRaw = dd.read_parquet('../data/extraction_sirene_20220510.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb18498",
   "metadata": {},
   "source": [
    "Temporaire : On restreint les données à 1% de la base initiales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "18d42b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DBRaw = DBRaw.sample(frac= 0.01, random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ebd953",
   "metadata": {},
   "source": [
    "On transforme les valeurs manquantes en NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "f109d898",
   "metadata": {},
   "outputs": [],
   "source": [
    "DBRaw = DBRaw.fillna(value=np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbec49e",
   "metadata": {},
   "source": [
    "On garde seulement les variables potentiellement intéressantes : \n",
    "- ``APE_SICORE :`` Code APE (Activité Principale Exercée) retenu lors du traitement de codification (soit Sicore soit gestionnaire) ;\n",
    "- ``NAT_SICORE :`` Nature de l'activité de l'entreprise ;\n",
    "- ``SED_SICORE :`` Sédentarité de l'entreprise ;\n",
    "- ``EVT_SICORE :`` Sédentarité de l'entreprise ;\n",
    "- ``LIB_SICORE :`` Sédentarité de l'entreprise ;\n",
    "- ``DATE :`` Sédentarité de l'entreprise ;\n",
    "- ``AUTO :`` Type de liasse extrait de la base brute Sirène ;\n",
    "- ``SURF :`` Surface en $m^2$ de l'établissement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "550efe05",
   "metadata": {},
   "outputs": [],
   "source": [
    "Var2Keep = [\"APE_SICORE\",\"LIB_SICORE\",\"AUTO\",\"DATE\",\"NAT_SICORE\",\"SED_SICORE\",\"EVT_SICORE\",\"SURF\"]\n",
    "DB = DBRaw[Var2Keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6338f6ef",
   "metadata": {},
   "source": [
    "On supprime les liasses où une valeur est manquante pour l'une de ces deux variables (6.77% de la base). Il s'agit principalement du code APE donc il n'est pas nécessaire de l'imputer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "921dbd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB = DB.dropna(subset=['APE_SICORE'])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ed07a1",
   "metadata": {},
   "source": [
    "On a finalement 10.8 millions de liasses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "252a27b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10887847"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DB.shape[0].compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7a6ff3",
   "metadata": {},
   "source": [
    "## I- Modèle 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94485c9",
   "metadata": {},
   "source": [
    "On estime un modèle FastText standard en utilisant seulement les libellés comme features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b69513",
   "metadata": {},
   "source": [
    "### 1) Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "4e191f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB1 = DB[[\"APE_SICORE\",\"LIB_SICORE\"]]\n",
    "DB1 = DB1.dropna(subset=['LIB_SICORE'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "b0b2a6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_ = set(stopwords.words('french') + ['a'])\n",
    "def CleanLib(lib):\n",
    "    # On supprime toutes les ponctuations\n",
    "    lib = lib.translate(str.maketrans(string.punctuation, ' ' * len(string.punctuation)))\n",
    "    # On supprime tous les chiffres\n",
    "    lib = lib.translate(str.maketrans(string.digits, ' ' * len(string.digits)))\n",
    "\n",
    "    # On supprime les stopwords et on renvoie les mots en majuscule\n",
    "    return \" \".join([x.lower() for x in lib.split() if x.lower() not in stopwords_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "7d247a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB1[\"LIB_CLEAN\"] = DB1[\"LIB_SICORE\"].apply(lambda x: CleanLib(x), meta=pd.Series(dtype='str', name='LIB_CLEAN'))\n",
    "df = DB1.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fb0e9e",
   "metadata": {},
   "source": [
    "### 2) Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8268132b",
   "metadata": {},
   "source": [
    "On mélange de manière aléatoire les index puis on les divise en 2 groupes selon un certain pourcentage (ici 80% et 20%)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4094786a",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123456)\n",
    "Idx = random.sample(df.index.values.tolist(), df.shape[0])\n",
    "Groups = np.split(Idx, [int(len(Idx)*0.8)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693b4426",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/train_text.txt\", 'w') as f:\n",
    "    for idx in range(len(Groups[0])):\n",
    "        aLine = \"__label__{} {}\".format(df.at[Groups[0][idx],\"APE_SICORE\"], df.at[Groups[0][idx],\"LIB_CLEAN\"])\n",
    "        f.write(\"%s\\n\" % aLine)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d5a745",
   "metadata": {},
   "source": [
    "### 3) Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f5fae1",
   "metadata": {},
   "source": [
    "On définit plusieurs options pour le modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6994b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_fasttext={\"dim\": 150,\n",
    "\"lr\": 0.2,\n",
    "\"epoch\": 80,\n",
    "\"wordNgrams\": 3,\n",
    "\"minn\": 3,\n",
    "\"maxn\": 4,\n",
    "\"minCount\": 3,\n",
    "\"bucket\": 3000000,\n",
    "\"thread\": 25,\n",
    "\"loss\": 'ova',\n",
    "\"label_prefix\": '__label__'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d9f244",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = fasttext.train_supervised(input=\"../data/train_text.txt\", **config_fasttext)\n",
    "#model1 = fasttext.load_model(\"../models/fasttextmodel1.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8673bd",
   "metadata": {},
   "source": [
    "### Evaluation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6024388",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred(lib, mod):\n",
    "    out = mod.predict(lib)\n",
    "    pred = out[0][0].replace(\"__label__\",\"\")\n",
    "    prob = out[1][0]\n",
    "    return [pred, prob]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb0fe9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"APE_SICORE\":\"APE_NIV5\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98521cfa",
   "metadata": {},
   "source": [
    "Accuracy of the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f78aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.loc[Groups[0], :]\n",
    "df_train[['PREDICTION_NIV5', 'PROBA']] = df_train['LIB_CLEAN'].swifter.apply(lambda x: get_pred(x, model1)).to_list()\n",
    "df_train['GoodPREDICTION'] = df_train['APE_NIV5'] == df_train['PREDICTION_NIV5']\n",
    "for i in range(2,5):\n",
    "    df_train['PREDICTION_NIV'+ str(i)] = df_train['PREDICTION_NIV5'].str[:i]\n",
    "    \n",
    "sum(df_train['GoodPREDICTION'])/df_train.shape[0] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf9a3e5",
   "metadata": {},
   "source": [
    "Accuracy of the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c94be99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.loc[Groups[1], :]\n",
    "df_test[['PREDICTION_NIV5', 'PROBA']] = df_test['LIB_CLEAN'].swifter.apply(lambda x: get_pred(x, model1)).to_list()\n",
    "df_test['GoodPREDICTION'] = df_test['APE_NIV5'] == df_test['PREDICTION_NIV5']\n",
    "for i in range(2,5):\n",
    "    df_test['PREDICTION_NIV'+ str(i)] = df_test['PREDICTION_NIV5'].str[:i]\n",
    "\n",
    "sum(df_test['GoodPREDICTION'])/df_test.shape[0] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd37f0db",
   "metadata": {},
   "source": [
    "On importe un document qui contient des informations sur les différents codes APE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700ded39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_naf =  pd.read_csv(r\"../data/naf_extended.csv\",sep=\",\",encoding=\"utf-8\",dtype=str)\n",
    "df_naf[[\"NIV3\",\"NIV4\",\"NIV5\"]] = df_naf[[\"NIV3\",\"NIV4\",\"NIV5\"]].apply(lambda x: x.str.replace('.', ''))\n",
    "df_naf.set_index(\"NIV5\", inplace=True, drop=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3110b60",
   "metadata": {},
   "source": [
    "On calcule la prédiction pour le niveau 1 grâce à la table importée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8900b930",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['PREDICTION_NIV1'] = df_test[\"PREDICTION_NIV2\"].swifter.apply(lambda x : pd.unique(df_naf[\"NIV1\"][df_naf[\"NIV2\"]== x])[0])\n",
    "df_train['PREDICTION_NIV1'] = df_train[\"PREDICTION_NIV2\"].swifter.apply(lambda x : pd.unique(df_naf[\"NIV1\"][df_naf[\"NIV2\"]== x])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a40ad1",
   "metadata": {},
   "source": [
    "On regarde la precision, le rappel et le F1 pour tous les différentes sous catégories du code APE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ecfb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for aNiv in tqdm([\"NIV1\",\"NIV2\",\"NIV3\",\"NIV4\"]):\n",
    "    df_test[\"APE_\" + aNiv] = df_test[\"APE_NIV5\"].apply(lambda x : df_naf.loc[x][aNiv])\n",
    "    df_train[\"APE_\" + aNiv] = df_train[\"APE_NIV5\"].apply(lambda x : df_naf.loc[x][aNiv])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0491ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(naf, train, test):\n",
    "    Results = dict()\n",
    "    for aNiv in [\"NIV1\",\"NIV2\",\"NIV3\", \"NIV4\", \"NIV5\"]:\n",
    "        Results[aNiv] = train.groupby(['APE_'+ aNiv]).size().rename(\"Size_TRAIN\").to_frame()\n",
    "        Results[aNiv] = Results[aNiv].join(test.groupby(['APE_'+ aNiv]).size().rename(\"Size_TEST\").to_frame())\n",
    "        Results[aNiv] = Results[aNiv].join(test.groupby(['APE_'+ aNiv]).mean('GoodPREDICTION').rename(columns={\"GoodPREDICTION\":\"Recall_TEST\"}))\n",
    "        Results[aNiv] = Results[aNiv].join(test.groupby(['PREDICTION_'+ aNiv]).mean('GoodPREDICTION').rename(columns={\"GoodPREDICTION\":\"Precision_TEST\"}))\n",
    "        Results[aNiv] = Results[aNiv].join(2 * 1/(1/Results[aNiv][\"Precision_TEST\"] + 1/Results[aNiv][\"Recall_TEST\"]).rename(\"F1_TEST\").to_frame())\n",
    "        Results[aNiv][\"LIB_\"+ aNiv] = [pd.unique(naf[\"LIB_\"+ aNiv][naf[aNiv]== x])[0] for x in Results[aNiv].index.values]\n",
    "\n",
    "    return Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848e7ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Results = get_results(df_naf, df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2266bc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "Results[\"NIV5\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cb625a",
   "metadata": {},
   "source": [
    "On calcule les matrices de confusion pour chaque catégories et sous catégorie afin de vérifier la prédiction au sein d'une même catégorie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f07b61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matrix(test, cat, mod):\n",
    "    sub_cat = \"NIV\" + str(int(cat[-1]) + 1 )\n",
    "    filtered_df = df_test[(df_test[\"APE_\" + cat] == mod) & (df_test[\"PREDICTION_\" + cat] == mod)]\n",
    "    cm = confusion_matrix(filtered_df[\"APE_\" + sub_cat].to_list(), filtered_df[\"PREDICTION_\" + sub_cat].to_list(), normalize = 'true')\n",
    "    return cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0397ec23",
   "metadata": {},
   "source": [
    "On regarde d'abord au niveau le plus aggrégé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa73110",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = np.sort(pd.unique(df_test[\"APE_NIV1\"]))\n",
    "fig, ax = plt.subplots(figsize=(20,8))\n",
    "sns.heatmap(confusion_matrix(df_test[\"APE_NIV1\"].to_list(), df_test[\"PREDICTION_NIV1\"].to_list(), normalize = 'true'),\n",
    "             annot=True, fmt='.2f',cmap='Blues', xticklabels=target_names, yticklabels=target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c87e8f",
   "metadata": {},
   "source": [
    "Ensuite on peut regarder les résultats au sein de chaque sous catégorie. Ci-dessous on s'intéresse à la ligne \"G\" et on vérifie comment sont prédit les codes au sein de cette catégorie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bcd91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfMatrices = {aNiv : {mod : get_matrix(df_test, aNiv, mod) for mod in pd.unique(df_test[\"APE_\" + aNiv])} for aNiv in [\"NIV1\",\"NIV2\",\"NIV3\",\"NIV4\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd5917a",
   "metadata": {},
   "outputs": [],
   "source": [
    "aNiv = \"NIV1\"\n",
    "aMod = \"Q\"\n",
    "\n",
    "aSubNiv = \"NIV\" + str(int(aNiv[-1]) + 1 )\n",
    "target_names = np.sort(pd.unique(df_test[\"APE_\" + aSubNiv][df_test[\"APE_\" + aNiv] == aMod]))\n",
    "fig, ax = plt.subplots(figsize=(20,8))\n",
    "sns.heatmap(ConfMatrices[aNiv][aMod], annot=True, fmt='.2f',cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03a455e",
   "metadata": {},
   "source": [
    "- hyper parametres\n",
    "- checker les libellés, leurs qualité, stats descr "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
