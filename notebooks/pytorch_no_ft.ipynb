{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test implémentation de FastText avec Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../src/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_orig = pd.read_parquet(\"../data/extraction_sirene_20220712.parquet\", engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_values = df_orig[\"APE_SICORE\"].unique().tolist()\n",
    "y_dict = {key: value for key, value in zip(distinct_values, range(len(distinct_values)))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "df = df_orig.sample(frac=0.0001, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1087, 20)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/mamba/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pytorch_classifier.pytorch_trainer import PytorchTrainer\n",
    "\n",
    "# Trainer module\n",
    "trainer = PytorchTrainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['AUTO', 'NAT_SICORE', 'SURF', 'EVT_SICORE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 3e-4\n",
    "PATIENCE = 5\n",
    "NUM_EPOCHS = 3\n",
    "\n",
    "params = {\n",
    "    \"num_epochs\": NUM_EPOCHS,\n",
    "    \"patience\": PATIENCE,\n",
    "    \"train_proportion\": 0.8,\n",
    "    \"batch_size\": 64,\n",
    "    \"learning_rate\": LEARNING_RATE,\n",
    "    \"buckets\": 2000000,\n",
    "    \"embedding_dim\": 120,\n",
    "    \"min_count\": 3,\n",
    "    \"min_n\": 3,\n",
    "    \"max_n\": 4,\n",
    "    \"word_ngrams\": 3,\n",
    "    \"sparse\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_classifier.pytorch_preprocessor import PytorchPreprocessor\n",
    "from src.constants import TEXT_FEATURE, Y\n",
    "\n",
    "pytorch_preprocessor = PytorchPreprocessor()\n",
    "df_train_py, df_test_py, df_gu_py = pytorch_preprocessor.preprocess(\n",
    "    df=df,\n",
    "    y=Y,\n",
    "    text_feature=TEXT_FEATURE,\n",
    "    categorical_features=categorical_features,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIB_SICORE</th>\n",
       "      <th>AUTO</th>\n",
       "      <th>NAT_SICORE</th>\n",
       "      <th>SURF</th>\n",
       "      <th>EVT_SICORE</th>\n",
       "      <th>APE_NIV1</th>\n",
       "      <th>APE_NIV2</th>\n",
       "      <th>APE_NIV3</th>\n",
       "      <th>APE_NIV4</th>\n",
       "      <th>APE_NIV5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LIA_NUM</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C14017958194</th>\n",
       "      <td>vent voitur occas produit diver march</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>G</td>\n",
       "      <td>45</td>\n",
       "      <td>451</td>\n",
       "      <td>4511</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X54014003089</th>\n",
       "      <td>apicultur</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>01</td>\n",
       "      <td>014</td>\n",
       "      <td>0149</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G69016531995</th>\n",
       "      <td>support patrimoin familial immobili san activi...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>L</td>\n",
       "      <td>68</td>\n",
       "      <td>683</td>\n",
       "      <td>6832</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C69018478430</th>\n",
       "      <td>commerc produit alimentair</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>G</td>\n",
       "      <td>47</td>\n",
       "      <td>471</td>\n",
       "      <td>4711</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G45017062449</th>\n",
       "      <td>construct immeubl vu vent</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>F</td>\n",
       "      <td>41</td>\n",
       "      <td>411</td>\n",
       "      <td>4110</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     LIB_SICORE  AUTO  \\\n",
       "LIA_NUM                                                                 \n",
       "C14017958194              vent voitur occas produit diver march     2   \n",
       "X54014003089                                          apicultur     9   \n",
       "G69016531995  support patrimoin familial immobili san activi...     2   \n",
       "C69018478430                         commerc produit alimentair     2   \n",
       "G45017062449                          construct immeubl vu vent     2   \n",
       "\n",
       "              NAT_SICORE  SURF  EVT_SICORE APE_NIV1 APE_NIV2 APE_NIV3  \\\n",
       "LIA_NUM                                                                 \n",
       "C14017958194           0     0           7        G       45      451   \n",
       "X54014003089           1     0           0        A       01      014   \n",
       "G69016531995           1     0           5        L       68      683   \n",
       "C69018478430           0     0           6        G       47      471   \n",
       "G45017062449           1     0           5        F       41      411   \n",
       "\n",
       "             APE_NIV4  APE_NIV5  \n",
       "LIA_NUM                          \n",
       "C14017958194     4511        44  \n",
       "X54014003089     0149       149  \n",
       "G69016531995     6832        78  \n",
       "C69018478430     4711       119  \n",
       "G45017062449     4110       269  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_py.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/3 [00:00<?, ?it/s]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to process 1 batch: 0.024994373321533203\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "SparseAdam does not support dense gradients, please consider Adam instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pytorch_classifier \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train_py\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTEXT_FEATURE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategorical_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/codification-ape/src/pytorch_classifier/pytorch_trainer.py:242\u001b[0m, in \u001b[0;36mPytorchTrainer.train\u001b[0;34m(self, df, y, text_feature, categorical_features, params)\u001b[0m\n\u001b[1;32m    239\u001b[0m best_val_loss \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39minf\n\u001b[1;32m    240\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(num_epochs)):\n\u001b[1;32m    241\u001b[0m     \u001b[39m# Steps\u001b[39;00m\n\u001b[0;32m--> 242\u001b[0m     train_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_step(dataloader\u001b[39m=\u001b[39;49mtrain_dataloader)\n\u001b[1;32m    243\u001b[0m     val_loss, _, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval_step(dataloader\u001b[39m=\u001b[39mval_dataloader)\n\u001b[1;32m    244\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscheduler\u001b[39m.\u001b[39mstep(val_loss)\n",
      "File \u001b[0;32m~/work/codification-ape/src/pytorch_classifier/pytorch_trainer.py:73\u001b[0m, in \u001b[0;36mPytorchTrainer.train_step\u001b[0;34m(self, dataloader)\u001b[0m\n\u001b[1;32m     70\u001b[0m backward_pass \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n\u001b[1;32m     72\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m---> 73\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer\u001b[39m.\u001b[39;49mstep()  \u001b[39m# Update weights\u001b[39;00m\n\u001b[1;32m     74\u001b[0m update \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n\u001b[1;32m     76\u001b[0m \u001b[39m# Cumulative Metrics\u001b[39;00m\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.9/site-packages/torch/optim/optimizer.py:113\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m    112\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 113\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.9/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.9/site-packages/torch/optim/sparse_adam.py:80\u001b[0m, in \u001b[0;36mSparseAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     78\u001b[0m params_with_grad\u001b[39m.\u001b[39mappend(p)\n\u001b[1;32m     79\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m p\u001b[39m.\u001b[39mgrad\u001b[39m.\u001b[39mis_sparse:\n\u001b[0;32m---> 80\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mSparseAdam does not support dense gradients, please consider Adam instead\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     81\u001b[0m grads\u001b[39m.\u001b[39mappend(p\u001b[39m.\u001b[39mgrad)\n\u001b[1;32m     83\u001b[0m state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate[p]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: SparseAdam does not support dense gradients, please consider Adam instead"
     ]
    }
   ],
   "source": [
    "pytorch_classifier = trainer.train(df_train_py, Y, TEXT_FEATURE, categorical_features, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_classifier.pytorch_evaluator import PytorchEvaluator\n",
    "\n",
    "evaluator = PytorchEvaluator(model=pytorch_classifier, tokenizer=trainer.tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = evaluator.evaluate(\n",
    "    df_test_py, Y, TEXT_FEATURE, categorical_features, 5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "3fa046f995eb80ac40c0869a1f9df46519f4ada8b8c395ef25dd1aa1a1a2fc63"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
