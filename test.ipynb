{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(\"src/\"))\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "import hydra\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from joblib import Memory\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "\n",
    "from evaluators import Evaluator\n",
    "from framework_classes import (\n",
    "    DATA_GETTER,\n",
    "    DATASETS,\n",
    "    LOSSES,\n",
    "    MODELS,\n",
    "    MODULES,\n",
    "    OPTIMIZERS,\n",
    "    PREPROCESSORS,\n",
    "    SCHEDULERS,\n",
    "    TOKENIZERS,\n",
    "    TRAINERS,\n",
    ")\n",
    "from models import FastTextWrapper\n",
    "from src.datasets import SoftClassifDataset\n",
    "from utils.data import PATHS, get_df_naf, get_file_system, get_processed_data, get_test_data, get_Y\n",
    "from utils.mappings import mappings\n",
    "from utils.mlflow import create_or_restore_experiment\n",
    "from utils.validation_viz import (\n",
    "    calibration_curve,\n",
    "    confidence_histogram,\n",
    "    get_automatic_accuracy,\n",
    "    sort_and_get_pred,\n",
    ")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = get_df_naf(revision=\"NAF2008\")\n",
    "\n",
    "display(df)\n",
    "# Define coefficients for each level\n",
    "similarity_coefficients = np.array([0.1, 0.1, 0.1, 0.1, 0.5])\n",
    "\n",
    "# Create a matrix of levels\n",
    "levels_matrix = df[['APE_NIV1', 'APE_NIV2', 'APE_NIV3', 'APE_NIV4', 'APE_NIV5']].values\n",
    "\n",
    "# Compute the similarity matrix using broadcasting\n",
    "similarity_matrix = np.dot((levels_matrix[:, None, :] == levels_matrix[None, :, :]), similarity_coefficients)\n",
    "\n",
    "# Convert the similarity matrix to a DataFrame for better readability\n",
    "similarity_df = pd.DataFrame(similarity_matrix, index=df['APE_NIV5'], columns=df['APE_NIV5'])\n",
    "\n",
    "similarity_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.APE_NIV3.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.mappings import mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_similarity_df = similarity_df.loc[mappings['apet_finale'].keys(), mappings['apet_finale'].keys()]\n",
    "# Map the APE_NIV5 codes to their order\n",
    "df['order'] = df['APE_NIV5'].map(mappings['apet_finale'])\n",
    "\n",
    "# Sort the DataFrame by the 'order' column\n",
    "ordered_df = df.sort_values('order').drop(columns='order')\n",
    "display(ordered_df)\n",
    "ordered_similarity_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revision = \"NAF2008\"\n",
    "model_class = \"torchFastText\"\n",
    "start_month = 1\n",
    "start_year = 2018\n",
    "text_feature = \"libelle\"\n",
    "textual_features_1 = \"NAT_LIB\"\n",
    "textual_features_2 = \"AGRI\"\n",
    "categorical_features_1 = \"TYP\"\n",
    "categorical_features_2 = \"NAT\"\n",
    "categorical_features_3 = \"SRF\"\n",
    "categorical_features_4 = \"CJ\"\n",
    "categorical_features_5 = \"CRT\"\n",
    "\n",
    "categorical_features = [categorical_features_1, categorical_features_2, categorical_features_3, categorical_features_4, categorical_features_5]\n",
    "cfg_dict = {\"data\": \n",
    "                {\"sirene\":\"sirene_4\", \n",
    "                \"start_month\": start_month, \n",
    "                \"start_year\": start_year, \n",
    "                \"revision\": revision,\n",
    "                \"text_feature\": text_feature,\n",
    "                \"textual_features\" : [textual_features_1, textual_features_2],\n",
    "                \"categorical_features\" : [categorical_features_1, categorical_features_2, categorical_features_3, categorical_features_4, categorical_features_5],}, \n",
    "                \n",
    "            \"model\":{\"model_name\": \"torchFastText\",\n",
    "                    \"preprocessor\": \"PyTorch\",\n",
    "                    \"model_params\" : {\"embedding_dim\": 80, \"categorical_embedding_dims\": 5, \"sparse\":False, \"direct_bagging\":False},\n",
    "                    \"train_params\": {\n",
    "                                        \"trainer_name\": \"Lightning\",\n",
    "                                        \"num_epochs\": 35,\n",
    "                                        \"patience_early_stopping\": 5,\n",
    "                                        \"batch_size\": 256,\n",
    "                                        \"optimizer_name\": \"Adam\",\n",
    "                                        \"optimizer_params\": {\n",
    "                                            \"lr\": 1e-3\n",
    "                                        },\n",
    "                                        \"scheduler_name\": \"ReduceLROnPlateau\",\n",
    "                                        \"scheduler_params\": {\n",
    "                                            \"factor\": 0.5,\n",
    "                                            \"patience\": 2,\n",
    "                                            \"min_lr\": 1e-6\n",
    "                                        },\n",
    "                                        \"loss_name\": \"CrossEntropyLoss\"\n",
    "                                        },\n",
    "                    \"test_params\": {\"test_batch_size\": 256, \"run_id\":'runs:/45afc22a961a4cdcb282aad93693326d/model'}},\n",
    "\n",
    "                \"tokenizer\": {\"tokenizer_name\": \"NGramTokenizer\",\n",
    "                            \"min_count\":100, \"min_n\":3, \"max_n\":6, \"len_word_ngrams\":3, \"num_tokens\":10000},\n",
    "            }\n",
    "cfg_dict_data = cfg_dict[\"data\"]\n",
    "df_naf = get_df_naf(revision=cfg_dict_data[\"revision\"])\n",
    "Y = get_Y(revision=cfg_dict[\"data\"][\"revision\"])\n",
    "df_train, df_val, df_test = get_processed_data(revision=cfg_dict[\"data\"][\"revision\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['MLFLOW_TRACKING_URI'] = \"https://projet-ape-mlflow.user.lab.sspcloud.fr/\" \n",
    "model_name = \"FastText-pytorch\"\n",
    "module = mlflow.pytorch.load_model(f\"models:/{model_name}/latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text, categorical_variables = (\n",
    "            df_test[text_feature].values,\n",
    "            df_test[categorical_features].values,\n",
    "        )\n",
    "\n",
    "dataset = SoftClassifDataset(\n",
    "    texts=text,\n",
    "    categorical_variables=categorical_variables,\n",
    "    tokenizer=module.model.tokenizer,\n",
    "    outputs=df_test[Y].values,\n",
    "    similarity_coefficients=[0.01, 0.1, 0.1, 0.1, 0.5],\n",
    "    revision=cfg_dict[\"data\"][\"revision\"],\n",
    ")\n",
    "dataloader = dataset.create_dataloader(\n",
    "    batch_size=10, shuffle=False, num_workers=12\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_train = df_train.sample(frac=0.001)\n",
    "df_val = df_val.sample(frac=0.01)\n",
    "df_test = df_test.sample(frac=0.01)\n",
    "\n",
    "train_text, train_categorical_variables = (\n",
    "            df_train[cfg_dict[\"data\"][\"text_feature\"]].values,\n",
    "            df_train[cfg_dict[\"data\"][\"categorical_features\"]].values,\n",
    "        )\n",
    "val_text, val_categorical_variables = (\n",
    "    df_val[cfg_dict[\"data\"][\"text_feature\"]].values,\n",
    "    df_val[cfg_dict[\"data\"][\"categorical_features\"]].values,\n",
    ")\n",
    "test_text, test_categorical_variables = (\n",
    "    df_test[cfg_dict[\"data\"][\"text_feature\"]].values,\n",
    "    df_test[cfg_dict[\"data\"][\"categorical_features\"]].values,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = TOKENIZERS[cfg_dict[\"tokenizer\"][\"tokenizer_name\"]](\n",
    "            **cfg_dict[\"tokenizer\"], training_text=train_text\n",
    "        )\n",
    "\n",
    "num_rows = tokenizer.num_tokens + tokenizer.get_nwords() + 1\n",
    "padding_idx = num_rows - 1\n",
    "num_classes = max(mappings[Y].values()) + 1\n",
    "categorical_vocab_sizes = []\n",
    "for feature in cfg_dict[\"data\"][\"categorical_features\"]:\n",
    "    if feature == \"SRF\":\n",
    "        categorical_vocab_sizes.append(5)\n",
    "    else:\n",
    "        categorical_vocab_sizes.append(max(mappings[feature].values()) + 1)\n",
    "\n",
    "model = MODELS[cfg_dict[\"model\"][\"model_name\"]](\n",
    "    **cfg_dict[\"model\"][\"model_params\"],\n",
    "    tokenizer=tokenizer,\n",
    "    num_rows=num_rows,\n",
    "    num_classes=num_classes,\n",
    "    categorical_vocabulary_sizes=categorical_vocab_sizes,\n",
    "    padding_idx=padding_idx,\n",
    ")\n",
    "\n",
    "loss = LOSSES[cfg_dict[\"model\"][\"train_params\"][\"loss_name\"]]()\n",
    "optimizer = OPTIMIZERS[\n",
    "    cfg_dict[\"model\"][\"train_params\"][\"optimizer_name\"]\n",
    "]  # without the () !\n",
    "scheduler = SCHEDULERS[cfg_dict[\"model\"][\"train_params\"][\"scheduler_name\"]]\n",
    "\n",
    "module = MODULES[cfg_dict[\"model\"][\"model_name\"]](\n",
    "    model=model,\n",
    "    loss=loss,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    **cfg_dict[\"model\"][\"train_params\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = TRAINERS[cfg_dict[\"model\"][\"train_params\"][\"trainer_name\"]](\n",
    "            **cfg_dict[\"model\"][\"train_params\"],\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_class = SoftClassifDataset\n",
    "\n",
    "\n",
    "train_dataset = dataset_class(\n",
    "    texts=train_text,\n",
    "    categorical_variables=train_categorical_variables,\n",
    "    tokenizer=tokenizer,\n",
    "    outputs=df_train[Y].values,\n",
    "    revision=cfg_dict[\"data\"][\"revision\"],\n",
    "    similarity_coefficients=similarity_coefficients,\n",
    ")\n",
    "val_dataset = dataset_class(\n",
    "    texts=val_text,\n",
    "    categorical_variables=val_categorical_variables,\n",
    "    tokenizer=tokenizer,\n",
    "    outputs=df_val[Y].values,\n",
    "    revision=cfg_dict[\"data\"][\"revision\"],\n",
    "    similarity_coefficients=similarity_coefficients,\n",
    ")\n",
    "\n",
    "test_dataset = dataset_class(\n",
    "    texts=test_text,\n",
    "    categorical_variables=test_categorical_variables,\n",
    "    tokenizer=tokenizer,\n",
    "    outputs=df_test[Y].values,\n",
    "    revision=cfg_dict[\"data\"][\"revision\"],\n",
    "    similarity_coefficients=similarity_coefficients,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = train_dataset.create_dataloader(\n",
    "    **cfg_dict[\"model\"][\"train_params\"]\n",
    ")\n",
    "val_dataloader = val_dataset.create_dataloader(**cfg_dict[\"model\"][\"train_params\"])\n",
    "test_dataloader = test_dataset.create_dataloader(\n",
    "    **cfg_dict[\"model\"][\"train_params\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_eval(df, dataloader, suffix='val'):\n",
    "    \"\"\"\n",
    "    Run evaluation on the given dataloader and log the results.\n",
    "    \"\"\"\n",
    "\n",
    "    predictions = trainer.predict(module, dataloader) # accumulates predictions over batches\n",
    "    predictions_tensor = torch.cat(predictions).cpu().numpy() # (num_test_samples, num_classes)\n",
    "\n",
    "    # Use your aggregation function\n",
    "    aggregated_results = Evaluator.get_aggregated_preds(\n",
    "        df=df,\n",
    "        Y=Y,\n",
    "        predictions=predictions_tensor,\n",
    "        top_k=1\n",
    "    )\n",
    "\n",
    "    display(aggregated_results)\n",
    "\n",
    "    accuracy = Evaluator.compute_accuracies(aggregated_preds=aggregated_results, suffix=suffix)\n",
    "\n",
    "    return aggregated_results\n",
    "\n",
    "run_eval(df_val, val_dataloader, suffix='val')\n",
    "run_eval(df_test, test_dataloader, suffix='test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
