{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append('src/')\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "import hydra\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from joblib import Memory\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "\n",
    "from framework_classes import (\n",
    "    DATA_GETTER,\n",
    "    DATASETS,\n",
    "    LOSSES,\n",
    "    MODELS,\n",
    "    MODULES,\n",
    "    OPTIMIZERS,\n",
    "    PREPROCESSORS,\n",
    "    SCHEDULERS,\n",
    "    TOKENIZERS,\n",
    "    TRAINERS,\n",
    ")\n",
    "from utils.data import get_df_naf, get_file_system, get_Y\n",
    "from utils.mappings import mappings\n",
    "from utils.mlflow import create_or_restore_experiment\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revision = \"NAF2008\"\n",
    "model_class = \"torchFastText\"\n",
    "start_month = 1\n",
    "start_year = 2018\n",
    "text_feature = \"libelle\"\n",
    "textual_features_1 = \"NAT_LIB\"\n",
    "textual_features_2 = \"AGRI\"\n",
    "categorical_features_1 = \"TYP\"\n",
    "categorical_features_2 = \"NAT\"\n",
    "categorical_features_3 = \"SRF\"\n",
    "categorical_features_4 = \"CJ\"\n",
    "categorical_features_5 = \"CRT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_dict = {\"data\": \n",
    "                {\"sirene\":\"sirene_4\", \n",
    "                \"start_month\": start_month, \n",
    "                \"start_year\": start_year, \n",
    "                \"revision\": revision,\n",
    "                \"text_feature\": text_feature,\n",
    "                \"textual_features\" : [textual_features_1, textual_features_2],\n",
    "                \"categorical_features\" : [categorical_features_1, categorical_features_2, categorical_features_3, categorical_features_4, categorical_features_5],}, \n",
    "                \n",
    "            \"model\":{\"name\": \"torchFastText\",\n",
    "                    \"preprocessor\": \"PyTorch\",}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_or_preprocess_data(cfg_dict_data, cfg_dict_model_preprocessor):\n",
    "    \"\"\"\n",
    "    Load and preprocess data, using joblib caching to avoid redundant computation.\n",
    "    \"\"\"\n",
    "    # Fetch data\n",
    "    df_s3, df_s4 = DATA_GETTER[cfg_dict_data[\"sirene\"]](**cfg_dict_data)\n",
    "    Y = get_Y(revision=cfg_dict_data[\"revision\"])\n",
    "    df_naf = get_df_naf(revision=cfg_dict_data[\"revision\"])\n",
    "\n",
    "    # Preprocess data\n",
    "    preprocessor = PREPROCESSORS[cfg_dict_model_preprocessor]()\n",
    "\n",
    "    if df_s4 is not None:\n",
    "        df_train_s4, df_val_s4, df_test = preprocessor.preprocess(\n",
    "            df=df_s4,\n",
    "            df_naf=df_naf,\n",
    "            y=Y,\n",
    "            text_feature=cfg_dict_data[\"text_feature\"],\n",
    "            textual_features=cfg_dict_data[\"textual_features\"],\n",
    "            categorical_features=cfg_dict_data[\"categorical_features\"],\n",
    "            test_size=0.1,\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"Sirene 4 data should be provided.\")\n",
    "\n",
    "    if df_s3 is not None:\n",
    "        df_train_s3, df_val_s3, df_test_s3 = preprocessor.preprocess(\n",
    "            df=df_s3,\n",
    "            df_naf=df_naf,\n",
    "            y=Y,\n",
    "            text_feature=cfg_dict_data[\"text_feature\"],\n",
    "            textual_features=cfg_dict_data[\"textual_features\"],\n",
    "            categorical_features=cfg_dict_data[\"categorical_features\"],\n",
    "            test_size=0.1,\n",
    "            s3=True,\n",
    "        )\n",
    "        # Merge Sirene 3 into the training set\n",
    "        df_s3_processed = pd.concat([df_train_s3, df_val_s3, df_test_s3])\n",
    "        df_train = pd.concat([df_s3_processed, df_train_s4]).reset_index(drop=True)\n",
    "\n",
    "        # Assert no data was lost\n",
    "        assert len(df_s3) == len(df_s3_processed)\n",
    "        assert len(df_train_s4) + len(df_s3) == len(df_train)\n",
    "\n",
    "    else:\n",
    "        df_train = df_train_s4\n",
    "\n",
    "    df_val = df_val_s4\n",
    "    return df_train, df_val, df_test, Y\n",
    "\n",
    "##### Data #########\n",
    "\n",
    "df_train, df_val, df_test, Y = load_or_preprocess_data(\n",
    "    cfg_dict[\"data\"], cfg_dict[\"model\"][\"preprocessor\"]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fs = get_file_system()\n",
    "file_path_train = \"projet-ape/model_comparison_splits/sirene4_20230101_20250211/df_train.parquet\"\n",
    "file_path_val = \"projet-ape/model_comparison_splits/sirene4_20230101_20250211/df_val.parquet\"\n",
    "file_path_test = \"projet-ape/model_comparison_splits/sirene4_20230101_20250211/df_test.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Start saving data')\n",
    "\n",
    "\n",
    "dfs = [df_train, df_val, df_test]\n",
    "file_paths = [file_path_train, file_path_val, file_path_test]\n",
    "\n",
    "for i, file_path in enumerate(file_paths):\n",
    "    dfs[i].libelle = dfs[i].libelle.astype(str)\n",
    "    dfs[i].to_parquet(file_path, filesystem=fs, index=False, engine=\"pyarrow\")\n",
    "\n",
    "print('Data saved')\n",
    "\n",
    "mlflow.log_param(\"number_of_training_observations\", df_train.shape[0])\n",
    "\n",
    "train_text, train_categorical_variables = (\n",
    "    df_train[cfg_dict[\"data\"][\"text_feature\"]].values,\n",
    "    df_train[cfg_dict[\"data\"][\"categorical_features\"]].values,\n",
    ")\n",
    "val_text, val_categorical_variables = (\n",
    "    df_val[cfg_dict[\"data\"][\"text_feature\"]].values,\n",
    "    df_val[cfg_dict[\"data\"][\"categorical_features\"]].values,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_read = pd.read_parquet(file_path_val,filesystem=fs)\n",
    "\n",
    "df_train_read"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
