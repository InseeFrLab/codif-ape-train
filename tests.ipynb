{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(\"src\"))\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "import hydra\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from joblib import Memory\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "\n",
    "from evaluators import torchFastTextEvaluator\n",
    "from framework_classes import (\n",
    "    DATA_GETTER,\n",
    "    DATASETS,\n",
    "    LOSSES,\n",
    "    MODELS,\n",
    "    MODULES,\n",
    "    OPTIMIZERS,\n",
    "    PREPROCESSORS,\n",
    "    SCHEDULERS,\n",
    "    TOKENIZERS,\n",
    "    TRAINERS,\n",
    ")\n",
    "from models import FastTextWrapper\n",
    "from utils.data import get_df_naf, get_file_system, get_processed_data, get_test_data, get_Y\n",
    "from utils.mappings import mappings\n",
    "from utils.mlflow import create_or_restore_experiment\n",
    "from utils.validation_viz import calibration_curve, confidence_histogram, sort_and_get_pred\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revision = \"NAF2008\"\n",
    "model_class = \"torchFastText\"\n",
    "start_month = 1\n",
    "start_year = 2018\n",
    "text_feature = \"libelle\"\n",
    "textual_features_1 = \"NAT_LIB\"\n",
    "textual_features_2 = \"AGRI\"\n",
    "categorical_features_1 = \"TYP\"\n",
    "categorical_features_2 = \"NAT\"\n",
    "categorical_features_3 = \"SRF\"\n",
    "categorical_features_4 = \"CJ\"\n",
    "categorical_features_5 = \"CRT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_dict = {\"data\": \n",
    "                {\"sirene\":\"sirene_4\", \n",
    "                \"start_month\": start_month, \n",
    "                \"start_year\": start_year, \n",
    "                \"revision\": revision,\n",
    "                \"text_feature\": text_feature,\n",
    "                \"textual_features\" : [textual_features_1, textual_features_2],\n",
    "                \"categorical_features\" : [categorical_features_1, categorical_features_2, categorical_features_3, categorical_features_4, categorical_features_5],}, \n",
    "                \n",
    "            \"model\":{\"name\": \"fastText\",\n",
    "                    \"preprocessor\": \"fastText\"}}\n",
    "cfg_dict_data = cfg_dict[\"data\"]\n",
    "df_naf = get_df_naf(revision=cfg_dict_data[\"revision\"])\n",
    "Y = get_Y(revision=revision)\n",
    "df_test_ls= get_test_data(**cfg_dict[\"data\"], y=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "logged_model = 'runs:/65bc7a269ea145248476b8c976090784/default'\n",
    "mlflow.set_tracking_uri(\"https://projet-ape-mlflow.user.lab.sspcloud.fr/\")\n",
    "# Load model as a PyFuncModel.\n",
    "fasttext = mlflow.pyfunc.load_model(logged_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext.predict(df_test_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "\n",
    "# Set the experiment ID or name\n",
    "mlflow.set_tracking_uri(\"https://projet-ape-mlflow.user.lab.sspcloud.fr/\")\n",
    "experiment_name = \"model_comparison_s4\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# Retrieve all runs for the experiment\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "runs_df = mlflow.search_runs(experiment_ids=[experiment.experiment_id])\n",
    "\n",
    "# Display the metrics\n",
    "print(runs_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = runs_df.filter(like=\"metrics.\")\n",
    "params_df = runs_df.filter(like=\"params.\")\n",
    "display(metrics_df)\n",
    "display(params_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_df.filter(like=\"num_trainable_parameters\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
