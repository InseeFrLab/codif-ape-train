{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(\"src/\"))\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "import hydra\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import yaml\n",
    "from hydra import initialize_config_dir\n",
    "from joblib import Memory\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "\n",
    "from evaluators import Evaluator\n",
    "from models import FastTextWrapper\n",
    "from src.datasets import SoftClassifDataset, TextClassificationDataModule\n",
    "from utils.data import PATHS, get_df_naf, get_file_system, get_processed_data, get_test_data, get_Y\n",
    "from utils.evaluation import (\n",
    "    get_fasttext_preds,\n",
    "    get_ground_truth,\n",
    "    get_label_mapping,\n",
    "    sort_and_get_pred,\n",
    ")\n",
    "from utils.mappings import mappings\n",
    "from utils.mlflow import create_or_restore_experiment\n",
    "from utils.validation_viz import (\n",
    "    calibration_curve,\n",
    "    confidence_histogram,\n",
    "    get_automatic_accuracy,\n",
    ")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['MLFLOW_TRACKING_URI'] = \"https://projet-ape-mlflow.user.lab.sspcloud.fr/\" \n",
    "# model_name = \"FastText-pytorch\"\n",
    "# module = mlflow.pytorch.load_model(f\"models:/{model_name}/latest\")\n",
    "\n",
    "run_id = \"01fd012d1d8f45828a889efd8cb926ec\"\n",
    "logged_model = f'runs:/{run_id}/model'\n",
    "# Load model as a PyFuncModel.\n",
    "module = mlflow.pytorch.load_model(logged_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the artifact directory (e.g., to a temp dir)\n",
    "local_artifacts_path = mlflow.artifacts.download_artifacts(run_id=run_id)\n",
    "\n",
    "# Load the YAML config\n",
    "with open(f\"{local_artifacts_path}/hydra_config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg: DictConfig = OmegaConf.create(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = hydra.utils.instantiate(cfg.model.trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = TextClassificationDataModule(\n",
    "                    cfg.data,\n",
    "                    cfg.tokenizer,\n",
    "                    cfg.dataset,\n",
    "                    batch_size = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = datamodule.val_dataloader()\n",
    "batch = next(iter(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trainer.predict(module, val_loader)\n",
    "predictions_tensor = torch.cat(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10000\n",
    "true_values = torch.tensor(datamodule.df_val.apet_finale[:n_samples].values).cuda()\n",
    "\n",
    "def high_proba_score(x, y):\n",
    "    scores = 1 - x[list(range(len(x))), y]\n",
    "    return scores\n",
    "\n",
    "manually_coding_mask = predictions_tensor[:n_samples].max(-1).values <= 0.65\n",
    "\n",
    "print(\"Taux de codification automatique : \", 1- (manually_coding_mask).float().mean().item())\n",
    "print('Nombre de samples utilisÃ©s pour calibration : ', len(predictions_tensor[:n_samples][manually_coding_mask]))\n",
    "scores = high_proba_score(predictions_tensor[:n_samples][manually_coding_mask].cuda(), true_values[manually_coding_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(scores)\n",
    "alpha = 0.05\n",
    "q_level = np.ceil((n+1)*(1-alpha))/n\n",
    "print(q_level)\n",
    "threshold_cp = torch.quantile(scores.float(), q_level, interpolation=\"higher\")\n",
    "print(threshold_cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = datamodule.test_dataloader()\n",
    "batch = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1 - module.predict_step(batch, 0).cpu() <= threshold_cp.cpu()).sum(dim = -1).float().mean()\n",
    "# (module.predict_step(batch, 0).cuda().sort(dim = -1, descending=True).values.cumsum(-1) <= threshold_cp).sum(dim = -1).float().mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
